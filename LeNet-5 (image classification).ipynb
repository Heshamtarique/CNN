{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeNet-5 consists of 7 layers â€“ alternatingly 2 convolutional and 2 average pooling layers, and then 2 fully connected layers and the output layer with activation function softmax. \n",
    "\n",
    "#### One more thing that can be noticed is-- \n",
    "#### only 50k of parameters are there to train but currently we have several millions of parameters. so we dropped the idea of using LeNet5 and the researchers switched to other architectures such as\n",
    "#### AlexNet\n",
    "#### VGG\n",
    "\n",
    "#### ResNet16 and ResNet19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## laodign MNIST datsset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reshapiing the image \n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the dataset\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)  \n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 6)         60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 13, 13, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               51328     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 53,558\n",
      "Trainable params: 53,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='tanh', input_shape=(28,28,1)))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='tanh'))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='tanh'))\n",
    "model.add(Dense(units=10, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2915 - accuracy: 0.9156 - val_loss: 0.1410 - val_accuracy: 0.9594\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1190 - accuracy: 0.9640 - val_loss: 0.0891 - val_accuracy: 0.9733\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0797 - accuracy: 0.9754 - val_loss: 0.0662 - val_accuracy: 0.9787\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0604 - accuracy: 0.9820 - val_loss: 0.0629 - val_accuracy: 0.9794\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0479 - accuracy: 0.9853 - val_loss: 0.0573 - val_accuracy: 0.9816\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0385 - accuracy: 0.9885 - val_loss: 0.0477 - val_accuracy: 0.9843\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0330 - accuracy: 0.9898 - val_loss: 0.0485 - val_accuracy: 0.9842\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 22s 11ms/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 0.0476 - val_accuracy: 0.9850\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.0442 - val_accuracy: 0.9849\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.0513 - val_accuracy: 0.9833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffe6892f850>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          epochs=10, \n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = model.predict(x_test)\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test[0],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
